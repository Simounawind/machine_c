{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZSjoT6zbsFJ"
   },
   "source": [
    "# Générer du texte avec des RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEIZgF4tzLON"
   },
   "source": [
    "Nous utiliserons pour cela un module adapté par Donald Dong qui permet d'entraîner rapidement un RNN pour la génération de texte, appelé `rnn-text-gen`. La documentation autour du module en question est [disponible sur Github](https://github.com/donaldong/rnn-text-gen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmPRRWmtcqvv"
   },
   "source": [
    "Contrairement au module `markovify`, nous n'allons pas installer le module et l'importer comme n'importe quel module Python. Nous allons ici devoir récupérer le répertoire git et l'importer ici.\n",
    "\n",
    "On commence pour cela par cloner le répertoire Git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XE8ASkti0HhU",
    "outputId": "17698028-19bb-49f6-9eb2-1825473b7294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "致命错误：目标路径 'rnn-text-gen' 已经存在，并且不是一个空目录。\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/donaldong/rnn-text-gen.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTtTSSKZ_U26"
   },
   "source": [
    "Pensez à remplacer le fichier 'text_generator.py' présent dans le répertoire 'rnn-text-gen/src' par le fichier disponible sur iCampus afin de pouvoir faire tourner le reste du code sous Tensorflow 2. Voir les détails de la manipulation sur iCampus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mMnEH10dCXB"
   },
   "source": [
    "Il nous faut alors dire au système (ici, notre système virtuel) où se trouve le module que l'on a récupé. On le fait à l'aide du code dans la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lOzf7goh0VWE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/content/rnn-text-gen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8QTsvQkdm-E"
   },
   "source": [
    "\n",
    "\n",
    "Il nous faut maintenant importer les classes et libraires pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iqFkQ0wYzFrS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 00:42:30.173424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.nn' has no attribute 'rnn_cell'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sl/dmcfd6sn2xz848jw02554ty40000gn/T/ipykernel_7896/2252977541.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNNTextGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machi/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \"\"\"\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machi/src/model_selector.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNNTextGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machi/src/text_generator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRNNTextGenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \"\"\"Creates a recurrent neural network with a tensorflow RNNCell cell (which\n\u001b[1;32m     10\u001b[0m     performs dynamic unrolling of the `inputs`). It has an output projection\n",
      "\u001b[0;32m~/Desktop/machi/src/text_generator.py\u001b[0m in \u001b[0;36mRNNTextGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mrnn_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasicRNNCell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mn_neurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.nn' has no attribute 'rnn_cell'"
     ]
    }
   ],
   "source": [
    "from src.text_generator import RNNTextGenerator\n",
    "from src.dataset import Dataset\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g0DY-49eFUB"
   },
   "source": [
    "*On* peut alors commencer à entraîner notre RNN.\n",
    "\n",
    "On commence par charger notre corpus d'entraînement. Ici, le module vient avec quelques corpus, dont on peut regarder rapidement à quoi ils ressemblent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZGTyqwjeRwe",
    "outputId": "9f4d0c3b-ef90-4c55-c73b-b63c03b43d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blanquette de veau\n",
      "{{Voir homonymes|Blanquette|Veau (homonymie)}}\n",
      "{{Infobox Mets\n",
      " | nom            = Blanquette de veau\n",
      " | image          = Blanquette de veau à l'ancienne 04.jpg\n",
      " | légende        = Blanquette de veau à l'ancienne et riz.\n",
      " | autre nom      = \n",
      " | lieu origine   = {{France}} \n",
      " | créateur       = \n",
      " | date           = Ancienne\n",
      " | place service  = [[Plat principal]]\n",
      " | température    = Chaude\n",
      " | ingrédients    = [[Viande]] de [[veau]], [[carotte]], [[poireau]], [[oignon grelot]], [[champignon de Paris]], [[Liaison (cuisine)|liée]] en [[sauce blanche]] à la [[crème fraîche|crème]] et au [[beurre]]\n",
      " | variations     = Cuisine à la [[Crème (produit laitier)|crème]], [[ragoût]], [[bœuf Stroganov]], [[poularde aux morilles]], [[daube provençale]], [[miroton de bœuf]]\n",
      " | accompagnement = [[Riz]], [[Pâtes alimentaires|pâtes]], [[pomme de terre|pommes de terre]], [[vin]] du [[Viticulture en France|vignoble français]] \n",
      " | classification = [[Cuisine française]]\n",
      "}}\n",
      "La '''blanquette'''\n"
     ]
    }
   ],
   "source": [
    "f = open('data/cuisine.txt')\n",
    "text = f.read()\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gl5gvPrikF1H"
   },
   "source": [
    "Il nous faut maintenant définir les paramètres d'entraînement. Parmi ces paramètres, on trouve :\n",
    "- La taille des batchs (batch_size)\n",
    "- La longueur des séquences (seq_length)\n",
    "- Le nombre d'époch (epoch)\n",
    "- Le taux d'apprentissage (learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pX_RwrTDePBk"
   },
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "learning_rate = 0.02\n",
    "epoch = 1\n",
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAWwKYzQkOzg"
   },
   "source": [
    "On peut alors traiter le corpus, c'est-à-dire créer les vecteurs qui serviront d'input au RNN. Le présent module propose par la fonction Dataset de transformer le corpus en un ensemble de batchs comprenant *n* séquences de longueur *j* de vecteurs one-hot (où *n* correspond à la valeur définie par batch_size, et *j* à la longueur des séquences définie par seq_length)\n",
    "\n",
    "Notons qu'ici, la fonction crée des vecteurs pour les caractères, mais on peut de façon générale choisir de faire des vecteurs pour les mots eux-mêmes et non les caractères.\n",
    "\n",
    "De même, les RNNs peuvent prendre en entrée des vecteurs de type *word embeddings*, mais nous nous limiterons ici aux vecteurs one-hot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZO-ZBDJskN6z",
    "outputId": "42730566-c629-4ad4-f14d-384ee60b9d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.dataset.Dataset object at 0x7fc42a9b88d0>\n"
     ]
    }
   ],
   "source": [
    "alice_dataset = Dataset(['data/cuisine.txt'], seq_length)\n",
    "print (alice_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koy7KvOrlEo_"
   },
   "source": [
    "On peut alors entraîner le modèle à l'aide de la fonction `RNNTextGenerator()`. Un argument important de cette fonction est le type d'unités que l'on utilise (ici BasicRNNCell). On pourra plus tard utiliser des unités de type LSTM ou GRU pour entraîner les réseaux de neurones correspondants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cckpjz4dzarw",
    "outputId": "91ccd78b-c34e-4b83-b265-41b9a9a99980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:76: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:102: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:105: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:110: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/xiaohua/opt/anaconda3/envs/machinec/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/xiaohua/opt/anaconda3/envs/machinec/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 00:29:00.705710: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-27 00:29:00.706511: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:115: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:139: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:143: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/xiaohua/Desktop/machi/src/text_generator.py:144: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNNTextGenerator(\n",
    "    seq_length,\n",
    "    alice_dataset.vocab_size,\n",
    "    rnn_cell=tf.compat.v1.nn.rnn_cell.LSTMCell,\n",
    "    learning_rate=learning_rate,\n",
    "    epoch=epoch,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guAfGKL9t8PY"
   },
   "source": [
    "Une façon d'évaluer nos paramètres et le degré de convergence de notre RNN consiste à voir comment évoluent la précision (Accuracy) et la fonction objectif (loss function).\n",
    "\n",
    "On commence par faire converger le modèle sur nos données, et on sauvegarde les scores dans une variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hUtLVZ1Jt8t_"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sl/dmcfd6sn2xz848jw02554ty40000gn/T/ipykernel_99516/3862406990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m rnn_model_scores = rnn_model.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0malice_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msave_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/Desktop/machi/src/text_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, save_scores)\u001b[0m\n\u001b[1;32m    186\u001b[0m                     feed_dict={\n\u001b[1;32m    187\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m                     },\n\u001b[1;32m    190\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/machinec/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/machinec/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/machinec/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/machinec/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/machinec/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/machinec/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_model_scores = rnn_model.fit(\n",
    "    alice_dataset,\n",
    "    save_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgKj-GaHvENk"
   },
   "source": [
    "On peut alors produire une visualisation graphique de l'évolution de ces scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "BSqOKcdKvHEc",
    "outputId": "c1f30d98-07cd-449a-e71a-81a749b2dfa6"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15, 6), ncols=2)\n",
    "rnn_model_scores['accuracy'].plot(\n",
    "    ax=axes[0], title='Accuracy (Train)'\n",
    ")\n",
    "rnn_model_scores['loss'].plot(\n",
    "    ax=axes[1], title='Loss (Train)'\n",
    ")\n",
    "for ax in axes:\n",
    "    ax.set(xlabel='Steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXOg9EozveVB"
   },
   "source": [
    "La courbe de la fonction objectif doit normalement une courbe descendante d'abord rapide puis qui ralentit. Si la courbe ne se stabilise cependant pas (qu'il y a beaucoup de pics par exemple), on considère que le RNN n'a pas convergé. Un modèle ne converge pas quand la fonction objectif ne se stabilise pas. Une raison à cette non-convergence peut s'expliquer par le nombre limité d'epochs (1) que nous avons fixé. On peut donc choisir de réentraîner notre RNN avec un nombre d'epochs plus élevé, par exemple.\n",
    "\n",
    "Sachez que l'on peut aussi affiner notre modèle sans le réentraîner de 0 en le va le 'fit' sur nos données (on peut considérer cela comme un epoch). On peut ainsi demander au modèle de s'affiner un certain nombre de fois, ou durant une certaine période, comme on le fait ci-dessous.\n",
    "\n",
    "De façon assez intéressante, on peut suivre l'évolution en direct de ces scores et de l'état de la prédiction en temps réel à mesure que le RNN s'entraîne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZXGLh_k36uh",
    "outputId": "021317b1-a256-4cea-a788-96392a0e6516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.579800009727478, test loss: 1.4071494340896606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/rnn-text-gen/src/text_generator.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self._tf_rnn_cell = rnn_cell(\n",
      "/content/rnn-text-gen/src/text_generator.py:115: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.compat.v1.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, but the\n",
      "Knave beck cealded the Mouse?' the March Hare.\n",
      "\n",
      "Alice looked upon and was hand, without was tif-\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# On importe la fonction native du module permettant de fixer une durée maximale à l'entraînement\n",
    "from src.time_limit import time_limit\n",
    "\n",
    "# On définit la durée de l'entraînement\n",
    "for _ in time_limit(seconds=30): \n",
    "  # On affine le modèle\n",
    "  rnn_model.fit(alice_dataset)\n",
    "  acc, loss = rnn_model.score(alice_dataset)\n",
    "  # On imprime à chaque epoch la précision et la valeur de la loss function\n",
    "  print('test acc: {}, test loss: {}'.format(\n",
    "        acc, loss\n",
    "    ))\n",
    "  # On demande à chaque epoch d'imprimer une séquence de 100 caractères prédits à partir de la séquence initiale 'Yes, but '\n",
    "  start_seq = 'Yes, but '\n",
    "  print(start_seq + rnn_model.generate(\n",
    "        alice_dataset,\n",
    "        start_seq,\n",
    "        100\n",
    "    ))\n",
    "  print('-----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgzov5cIyd4Z"
   },
   "source": [
    "Quelque soit la performance de votre RNN, il est en tout cas déjà prêt pour la génération de phrase. Générer une séquence se fait à l'aide de la fonction `generate()`. La fonction prend en argument le dataset (c'est-à-dire le dictionnaire contenant les équivalences entre les vecteurs one-hot et les symboles correspondants), la séquence à partir de laquelle prédire, et le nombre de caractères à prédire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svVaARimBQH_",
    "outputId": "cf32c249-7277-4667-c12c-3a311be122a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course beht quite as\n",
      "she only deares as preaced himely.\n",
      "\n",
      "'I'm\n",
      "and not, me almos. The natched intind about the Sea-bless?' said the Mouse, what usuoped optor,' the Dodo,\n",
      "way just\n",
      "all fir at the Knall reme!'\n",
      "I want to the went on this: was it my way with their to:\n",
      "'I never coppreach criam there is a routs he\n",
      "dreadly way?' said the Hattier, croseding man, that and\n",
      "fiued the creacle peglind deal something on the\n",
      "jury did talking at the Dodow midd silbing in tit!' Ger execute beht some say that sooting hand\n"
     ]
    }
   ],
   "source": [
    "# Pour des raisons de lisibilité, on définit la séquence d'amorce dans une variable à part\n",
    "start_seq = 'Of course '\n",
    "\n",
    "# On imprime ici directement l'amorce et le texte généré (mais on pourrait enregistrer le texte généré dans une variable par exemple)\n",
    "print(start_seq + rnn_model.generate(\n",
    "        alice_dataset,\n",
    "        start_seq,\n",
    "        500\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qygj-jafzUax"
   },
   "source": [
    "Comme dit plus haut, vous pouvez entraîner des RNN plus spécifiques, à savoir des LSTM et des réseaux de type GRU. Il suffit pour cela notamment de remplacer dans la fonction d'entraînement le `BasicRNNCell` par `LSTMCell` ou `GRUCell` (et modifier les valeurs des autres arguments si besoin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j22GJOfj1ltf"
   },
   "source": [
    "## Exercice\n",
    "\n",
    "- Quels sont les paramètres qui vous permettent d'améliorer les résultats pour un petit corpus ?\n",
    "- Quel est l'impact de la taille du corpus ?\n",
    "- Quelle est la performance du RNN sur la prédiction du wikiCréole ?\n",
    "- Quel est le type de réseau de neurones qui marche le mieux (sur vos données) ?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
